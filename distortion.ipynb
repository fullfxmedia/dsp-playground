{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded3a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Audio, display\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_waveform(waveform, sr, other=None, channel=0, start=0, end=2000, show_fft=False):\n",
    "    \"\"\"\n",
    "    Plot a waveform (and optionally a second one for comparison).\n",
    "    \n",
    "    Args:\n",
    "        waveform (np.ndarray): Array of shape (channels, samples)\n",
    "        sr (int): Sample rate\n",
    "        other (np.ndarray, optional): Second waveform to compare, same shape as waveform\n",
    "        channel (int): Which channel to plot (default=0)\n",
    "        start (int): Start sample index\n",
    "        end (int): End sample index\n",
    "        show_fft (bool): Whether to also plot frequency spectra\n",
    "    \"\"\"\n",
    "    # Time axis in seconds\n",
    "    samples = waveform.shape[1]\n",
    "    end = min(end, samples)\n",
    "    t = np.arange(start, end) / sr\n",
    "\n",
    "    plt.figure(figsize=(12, 5 if not show_fft else 10))\n",
    "\n",
    "    # --- Time-domain plot ---\n",
    "    plt.subplot(2 if show_fft else 1, 1, 1)\n",
    "    plt.plot(t, waveform[channel, start:end], label=\"Original\")\n",
    "    if other is not None:\n",
    "        plt.plot(t, other[channel, start:end], label=\"Processed\", alpha=0.8)\n",
    "    plt.title(f\"Waveform (Channel {channel})\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.legend()\n",
    "\n",
    "    # --- Frequency-domain plot ---\n",
    "    if show_fft:\n",
    "        fft_orig = np.fft.rfft(waveform[channel])\n",
    "        freqs = np.fft.rfftfreq(samples, 1/sr)\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.semilogy(freqs, np.abs(fft_orig), label=\"Original\")\n",
    "        if other is not None:\n",
    "            fft_proc = np.fft.rfft(other[channel])\n",
    "            plt.semilogy(freqs, np.abs(fft_proc), label=\"Processed\", alpha=0.5)\n",
    "        plt.title(\"Frequency Spectrum\")\n",
    "        plt.xlabel(\"Frequency [Hz]\")\n",
    "        plt.ylabel(\"Magnitude\")\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9b4f45",
   "metadata": {},
   "source": [
    "# Original Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a905f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_len = 5000 # 5 seconds\n",
    "channels = 2  # Stereo audio\n",
    "sr = 44100 # stream rate\n",
    "audio_path = \"resources/audio1_pitchshift_input.wav\"\n",
    "\n",
    "sr_loaded, y = wavfile.read(audio_path)  # y has shape (samples, channels) if stereo\n",
    "\n",
    "# Convert to float32 and shape to (channels, samples)\n",
    "waveform = y.T.astype(np.float32) / np.max(np.abs(y))  # normalize\n",
    "num_samples = waveform.shape[1]\n",
    "print(f\"Original length: {num_samples} samples, Sample rate: {sr_loaded} Hz\")\n",
    "display(Audio(waveform, rate=sr))\n",
    "\n",
    "plot_waveform(waveform, sr, other=waveform, channel=0, show_fft=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829465d3",
   "metadata": {},
   "source": [
    "# Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f047dcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "distort_amount = 2.0  # Distortion amount\n",
    "\n",
    "# Apply distortion via tanh function\n",
    "waveform_distorted = np.tanh(distort_amount * waveform)\n",
    "\n",
    "# Normalize to -1 < 0 < -1 to prevent clipping\n",
    "max_val = np.max(np.abs(waveform_distorted))\n",
    "if max_val > 1.0:\n",
    "    waveform_distorted = waveform_distorted / max_val\n",
    "\n",
    "output_wav = waveform_distorted.T\n",
    "wav_int16 = np.int16(output_wav / np.max(np.abs(output_wav)) * 32767)\n",
    "wavfile.write(\"out/audio1_distorted.wav\", sr, wav_int16)\n",
    "\n",
    "display(Audio(waveform_distorted, rate=sr))\n",
    "plot_waveform(waveform, sr, other=waveform_distorted, channel=0, show_fft=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f1202b",
   "metadata": {},
   "source": [
    "# Distortion + Envelope Follower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e92111",
   "metadata": {},
   "outputs": [],
   "source": [
    "attackCoeff = 0.8  # Attack coefficient\n",
    "releaseCoeff = 0.5 # Release coefficient\n",
    "env = 0.0  # Initialize envelope\n",
    "waveform_env = np.zeros((channels, num_samples))\n",
    "\n",
    "env = np.zeros(channels)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    for ch in range(channels):\n",
    "        # input magnitude\n",
    "        input_magnitude = np.abs(waveform[ch][i])\n",
    "\n",
    "        # Envelope follower with attack and release\n",
    "        if input_magnitude > env[ch]:\n",
    "            env[ch] = attackCoeff * env[ch] + (1.0 - attackCoeff) * input_magnitude\n",
    "        else:\n",
    "            env[ch] = releaseCoeff * env[ch] + (1.0 - releaseCoeff) * input_magnitude\n",
    "\n",
    "        # Apply distortion and smooth with envelope\n",
    "        waveform_env[ch][i] = np.tanh(waveform[ch][i] * (1.0 + env[ch] * distort_amount))\n",
    "\n",
    "display(Audio(waveform_env, rate=sr))\n",
    "plot_waveform(waveform, sr, other=waveform_env, channel=0, show_fft=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
